{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c408ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import utils\n",
    "from models.trajfm import TrajFM\n",
    "from data import TrajFMDataset, PretrainPadder, fetch_task_padder, X_COL, Y_COL, coord_transform_GPS_UTM\n",
    "from torch.utils.data import random_split\n",
    "import warnings\n",
    "from pipeline import train_user_model, test_user_model\n",
    "import torch.multiprocessing as mp\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84217ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "SETTINGS_CACHE_DIR = os.environ.get('SETTINGS_CACHE_DIR', os.path.join('settings', 'cache'))\n",
    "MODEL_CACHE_DIR = os.environ.get('MODEL_CACHE_DIR', 'saved_model')\n",
    "LOG_SAVE_DIR = os.environ.get('LOG_SAVE_DIR', 'logs')\n",
    "PRED_SAVE_DIR = os.environ.get('PRED_SAVE_DIR', 'predictions')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
    "\n",
    "\n",
    "if mp.get_start_method(allow_none=True) is None:\n",
    "    mp.set_start_method('spawn')\n",
    "device = f'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "torch.backends.cuda.enable_math_sdp(True)\n",
    "# This key is an indicator of multiple things.\n",
    "datetime_key = utils.get_datetime_key()\n",
    "\n",
    "\n",
    "with open(os.path.join('settings', f'local_test.json'), 'r') as fp:\n",
    "    setting = json.load(fp)\n",
    "    setting = setting[0]\n",
    "utils.create_if_noexists(SETTINGS_CACHE_DIR)\n",
    "with open(os.path.join(SETTINGS_CACHE_DIR, f'{datetime_key}.json'), 'w') as fp:\n",
    "    json.dump(setting, fp)\n",
    "    \n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71773187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: ./dataset/geolife_U56_TrajAll_L1000.h5\n"
     ]
    }
   ],
   "source": [
    "# pyright: ignore[reportIndexIssue]\n",
    "SAVE_NAME = setting[\"save_name\"]\n",
    "\n",
    "train_traj_df = pd.read_hdf(setting['dataset']['train_traj_df'], key='trips')\n",
    "print(\"dataset:\", setting['dataset']['train_traj_df'])\n",
    "user_count = len(train_traj_df['user_id'].unique())\n",
    "traj_count = len(train_traj_df['traj_id'].unique())\n",
    "traj_len = len(train_traj_df['seq_i'])\n",
    "tao = train_traj_df['delta_t'].mean()\n",
    "setting[\"finetune\"][\"padder\"][\"params\"][\"num_users\"] = user_count\n",
    "\n",
    "scale = 4000\n",
    "# if \"chengdu\" in setting['dataset']['train_traj_df']:\n",
    "#     UTM_region = 48\n",
    "# if \"xian\" in setting['dataset']['train_traj_df']:\n",
    "#     UTM_region = 49\n",
    "if \"geolife\" in setting['dataset']['train_traj_df']:\n",
    "    UTM_region = 50  \n",
    "train_dataset = TrajFMDataset(traj_df=train_traj_df, UTM_region=UTM_region, scale = scale)\n",
    "\n",
    "poi_df = pd.read_hdf(setting['dataset']['poi_df'], key='pois')\n",
    "poi_embed = torch.from_numpy(np.load(setting['dataset']['poi_embed'])).float().to(device)\n",
    "\n",
    "poi_coors = poi_df[[X_COL, Y_COL]].to_numpy()\n",
    "poi_coors = (coord_transform_GPS_UTM(poi_coors, UTM_region) - train_dataset.spatial_middle_coord) / scale\n",
    "poi_coors = torch.tensor(poi_coors).float().to(device)\n",
    "\n",
    "# Build the learnable model.\n",
    "trajfm = TrajFM(poi_embed=poi_embed, \n",
    "                poi_coors=poi_coors, \n",
    "                UTM_region=UTM_region,\n",
    "                spatial_middle_coord = train_dataset.spatial_middle_coord, \n",
    "                scale = scale, \n",
    "                **setting['trajfm'],\n",
    "                user = user_count).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62886f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users : 56\n",
      "total_traj : 7602\n",
      "total_points : 5450141\n",
      "avg_traj_len : 1.62 hours\n",
      "Data Filtering : ['25th to 75th quartile based on traj_len', 'traj_len > 30 points', 'delta_t > 1800s', 'traj/user > 35 traj', 'resampled traj to 1000 points max', 'user_number and seq_i recalculated']\n"
     ]
    }
   ],
   "source": [
    "data_summary = {\n",
    "    \"users\": user_count,\n",
    "    \"total_traj\": traj_count,           \n",
    "    \"total_points\": traj_len,\n",
    "    \"avg_traj_len\": f\"{round(tao/3600, 2)} hours\",\n",
    "    \"Data Filtering\": [ \n",
    "        \"25th to 75th quartile based on traj_len\", \n",
    "        \"traj_len > 30 points\", \n",
    "        \"delta_t > 1800s\",\n",
    "        \"traj/user > 35 traj\",\n",
    "        \"resampled traj to 1000 points max\",\n",
    "        \"user_number and seq_i recalculated\",]\n",
    "}\n",
    "\n",
    "for key, value in data_summary.items():\n",
    "    print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e20c8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(train_dataset)\n",
    "train_size = int(0.6 * total_size)\n",
    "val_test_size = total_size - train_size\n",
    "val_size = int(0.5 * val_test_size)\n",
    "test_size = val_test_size - val_size\n",
    "\n",
    "train_dataset, val_test_dataset = random_split(train_dataset, [train_size, val_test_size])\n",
    "val_dataset, test_dataset = random_split(val_test_dataset, [val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d56d6463",
   "metadata": {},
   "outputs": [],
   "source": [
    "downstreamtask = setting['finetune']['padder']['name']    \n",
    "padder = fetch_task_padder(padder_name=setting['finetune']['padder']['name'], padder_params=setting['finetune']['padder']['params'])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, collate_fn=padder, **setting['finetune']['dataloader'])\n",
    "val_dataloader = DataLoader(val_dataset, collate_fn=padder, **setting['finetune']['dataloader'])\n",
    "test_dataloader = DataLoader(test_dataset, collate_fn=padder, **setting['finetune']['dataloader'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca23fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found, starting new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meuj01\u001b[0m (\u001b[33mSP_001\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/teamspace/studios/this_studio/wandb/run-20250425_154051-U56_TrajAll_L1000_v5.2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/SP_001/TrajFM%20TUL/runs/U56_TrajAll_L1000_v5.2' target=\"_blank\">U56_TrajAll_L1000_v5.2</a></strong> to <a href='https://wandb.ai/SP_001/TrajFM%20TUL' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/SP_001/TrajFM%20TUL' target=\"_blank\">https://wandb.ai/SP_001/TrajFM%20TUL</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/SP_001/TrajFM%20TUL/runs/U56_TrajAll_L1000_v5.2' target=\"_blank\">https://wandb.ai/SP_001/TrajFM%20TUL/runs/U56_TrajAll_L1000_v5.2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run id is U56_TrajAll_L1000_v5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 48/48 [00:27<00:00,  1.75it/s]\n",
      "Training, avg loss: 3.668:   2%|▏         | 1/60 [01:19<1:17:42, 79.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 18.36%,\n",
      "ACC@5: 38.48%,\n",
      "Macro-R: 6.74%,\n",
      "Macro-P: 1.93%,\n",
      "Macro-F1: 2.9%,\n",
      "val_loss 3.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 48/48 [00:27<00:00,  1.75it/s].02s/it]\n",
      "Training, avg loss: 3.454:   3%|▎         | 2/60 [02:36<1:15:43, 78.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 18.36%,\n",
      "ACC@5: 39.52%,\n",
      "Macro-R: 5.62%,\n",
      "Macro-P: 1.62%,\n",
      "Macro-F1: 2.26%,\n",
      "val_loss 3.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 48/48 [00:27<00:00,  1.76it/s].34s/it]\n",
      "Training, avg loss: 3.355:   5%|▌         | 3/60 [03:54<1:14:00, 77.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 19.92%,\n",
      "ACC@5: 40.49%,\n",
      "Macro-R: 6.68%,\n",
      "Macro-P: 2.1%,\n",
      "Macro-F1: 2.94%,\n",
      "val_loss 3.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 48/48 [00:27<00:00,  1.73it/s].90s/it]\n",
      "Training, avg loss: 3.275:   7%|▋         | 4/60 [05:12<1:12:47, 77.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 21.74%,\n",
      "ACC@5: 43.1%,\n",
      "Macro-R: 8.03%,\n",
      "Macro-P: 3.22%,\n",
      "Macro-F1: 3.91%,\n",
      "val_loss 3.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 48/48 [00:27<00:00,  1.74it/s].99s/it]\n",
      "Training, avg loss: 3.224:   8%|▊         | 5/60 [06:30<1:11:29, 78.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 22.59%,\n",
      "ACC@5: 43.55%,\n",
      "Macro-R: 8.51%,\n",
      "Macro-P: 3.68%,\n",
      "Macro-F1: 4.64%,\n",
      "val_loss 3.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 48/48 [00:27<00:00,  1.72it/s].00s/it]\n",
      "Training, avg loss: 3.175:  10%|█         | 6/60 [07:48<1:10:20, 78.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 19.73%,\n",
      "ACC@5: 42.58%,\n",
      "Macro-R: 7.7%,\n",
      "Macro-P: 3.4%,\n",
      "Macro-F1: 4.33%,\n",
      "val_loss 3.292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "file_path = f\"saved_model/{SAVE_NAME}.{downstreamtask}\"\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"Loading model {file_path}\")\n",
    "    trajfm.load_state_dict(torch.load(os.path.join(MODEL_CACHE_DIR, f'{SAVE_NAME}.{downstreamtask}'), map_location=device))\n",
    "else:\n",
    "    print(\"Model not found, starting new\")\n",
    "\n",
    "train_log, saved_model_state_dict = train_user_model(model=trajfm, \n",
    "                                                    train_dataloader=train_dataloader, \n",
    "                                                    val_dataloader=val_dataloader,\n",
    "                                                    device = device, \n",
    "                                                    **setting['finetune']['config'],\n",
    "                                                    data_summary = data_summary)\n",
    "\n",
    "if setting['finetune'].get('save', False):\n",
    "    # save model\n",
    "    utils.create_if_noexists(MODEL_CACHE_DIR)\n",
    "    torch.save(saved_model_state_dict, os.path.join(MODEL_CACHE_DIR, f'{SAVE_NAME}.{downstreamtask}'))\n",
    "    \n",
    "    # save log\n",
    "    log_dir = os.path.join(LOG_SAVE_DIR, SAVE_NAME)\n",
    "    utils.create_if_noexists(log_dir)\n",
    "    log_path = os.path.join(log_dir, f'{SAVE_NAME}_{downstreamtask}.csv')\n",
    "    file_exists = os.path.exists(log_path)\n",
    "    train_log.to_csv(log_path, mode='a', header=not file_exists, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdedca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, _ = test_user_model(model=trajfm, dataloader=test_dataloader, device = device)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {round(value * 100, 2)}%,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f798cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([{\n",
    "    \"Model\": f\"{SAVE_NAME}\",\n",
    "    **{key: round(value * 100, 2) for key, value in metrics.items()}\n",
    "}])\n",
    "\n",
    "csv_path = \"logs/test.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "else:\n",
    "    df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
