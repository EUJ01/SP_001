{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c408ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import utils\n",
    "from models.trajfm import TrajFM\n",
    "from data import TrajFMDataset, PretrainPadder, fetch_task_padder, X_COL, Y_COL, coord_transform_GPS_UTM\n",
    "from torch.utils.data import random_split\n",
    "import warnings\n",
    "from pipeline import train_user_model, test_user_model\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84217ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "SETTINGS_CACHE_DIR = os.environ.get('SETTINGS_CACHE_DIR', os.path.join('settings', 'cache'))\n",
    "MODEL_CACHE_DIR = os.environ.get('MODEL_CACHE_DIR', 'saved_model')\n",
    "LOG_SAVE_DIR = os.environ.get('LOG_SAVE_DIR', 'logs')\n",
    "PRED_SAVE_DIR = os.environ.get('PRED_SAVE_DIR', 'predictions')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)  # Add this line for CUDA\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
    "torch.multiprocessing.set_start_method('spawn')\n",
    "device = f'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "torch.backends.cuda.enable_math_sdp(True)\n",
    "# This key is an indicator of multiple things.\n",
    "datetime_key = utils.get_datetime_key()\n",
    "\n",
    "# Load the settings file, and save a backup in the cache directory.\n",
    "with open(os.path.join('settings', f'local_test.json'), 'r') as fp:\n",
    "    settings = json.load(fp)\n",
    "utils.create_if_noexists(SETTINGS_CACHE_DIR)\n",
    "with open(os.path.join(SETTINGS_CACHE_DIR, f'{datetime_key}.json'), 'w') as fp:\n",
    "    json.dump(settings, fp)\n",
    "    \n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71773187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===SETTING 0/1===\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the multiple settings.\n",
    "for setting_i, setting in enumerate(settings):\n",
    "    SAVE_NAME = setting.get('save_name', None)\n",
    "    \n",
    "    train_traj_df = pd.read_hdf(setting['dataset']['train_traj_df'], key='trips')\n",
    "    print(\"dataset:\", setting['dataset']['train_traj_df'])\n",
    "\n",
    "    scale = 4000\n",
    "    # if \"chengdu\" in setting['dataset']['train_traj_df']:\n",
    "    #     UTM_region = 48\n",
    "    # if \"xian\" in setting['dataset']['train_traj_df']:\n",
    "    #     UTM_region = 49\n",
    "    if \"geolife\" in setting['dataset']['train_traj_df']:\n",
    "        UTM_region = 50\n",
    "            \n",
    "    train_dataset = TrajFMDataset(traj_df=train_traj_df, UTM_region=UTM_region, scale = scale)\n",
    "    \n",
    "    poi_df = pd.read_hdf(setting['dataset']['poi_df'], key='pois')\n",
    "    poi_embed = torch.from_numpy(np.load(setting['dataset']['poi_embed'])).float().to(device)\n",
    "    \n",
    "    poi_coors = poi_df[[X_COL, Y_COL]].to_numpy()\n",
    "    poi_coors = (coord_transform_GPS_UTM(poi_coors, UTM_region) - train_dataset.spatial_middle_coord) / scale\n",
    "    poi_coors = torch.tensor(poi_coors).float().to(device)\n",
    "\n",
    "    # Build the learnable model.\n",
    "    trajfm = TrajFM(poi_embed=poi_embed, \n",
    "                    poi_coors=poi_coors, \n",
    "                    UTM_region=UTM_region,\n",
    "                    spatial_middle_coord = train_dataset.spatial_middle_coord, \n",
    "                    scale = scale, \n",
    "                    **setting['trajfm'],\n",
    "                    user = setting[\"finetune\"][\"padder\"][\"params\"][\"num_users\"]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62886f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  22  23  24  25  26  28  29  30  34  35  36  37  38  39  41  42\n",
      "  43  44  46  50  51  52  56  62  65  67  68  71  73  74  78  81  82  83\n",
      "  84  85  88  89  91  92  95  96  97 101 102 103 104 111 112 113 115 119\n",
      " 125 126 128 134 140 141 142 144 147 153 154 155 163 167 168 169 174 179]\n"
     ]
    }
   ],
   "source": [
    "user_count = len(train_traj_df['user_id'].unique()))\n",
    "traj_count = len(train_traj_df['traj_id'].unique())\n",
    "traj_len = len(train_traj_df['seq_i'])\n",
    "tao = train_traj_df['delta_t'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ac228c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e20c8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(train_dataset)\n",
    "train_size = int(0.6 * total_size)\n",
    "val_test_size = total_size - train_size\n",
    "val_size = int(0.5 * val_test_size)\n",
    "test_size = val_test_size - val_size\n",
    "\n",
    "train_dataset, val_test_dataset = random_split(train_dataset, [train_size, val_test_size])\n",
    "val_dataset, test_dataset = random_split(val_test_dataset, [val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d6463",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading model {SAVE_NAME}.pretrain\")\n",
    "downstreamtask = setting['finetune']['padder']['name']\n",
    "trajfm.load_state_dict(torch.load(os.path.join(MODEL_CACHE_DIR, f'{SAVE_NAME}.{downstreamtask}'), map_location=device))\n",
    "\n",
    "padder = fetch_task_padder(padder_name=setting['finetune']['padder']['name'], padder_params=setting['finetune']['padder']['params'])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, collate_fn=padder, **setting['finetune']['dataloader'])\n",
    "val_dataloader = DataLoader(val_dataset, collate_fn=padder, **setting['finetune']['dataloader'])\n",
    "test_dataloader = DataLoader(test_dataset, collate_fn=padder, **setting['finetune']['dataloader'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca23fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log, saved_model_state_dict = train_user_model(model=trajfm, \n",
    "                                                        train_dataloader=train_dataloader, \n",
    "                                                        val_dataloader=val_dataloader,\n",
    "                                                        device = device, \n",
    "                                                        **setting['finetune']['config'])\n",
    "\n",
    "if setting['finetune'].get('save', False):\n",
    "    # save model\n",
    "    utils.create_if_noexists(MODEL_CACHE_DIR)\n",
    "    torch.save(saved_model_state_dict, os.path.join(MODEL_CACHE_DIR, f'{SAVE_NAME}.{downstreamtask}'))\n",
    "    \n",
    "    # save log\n",
    "    log_dir = os.path.join(LOG_SAVE_DIR, SAVE_NAME)\n",
    "    utils.create_if_noexists(log_dir)\n",
    "    log_path = os.path.join(log_dir, f'{SAVE_NAME}_{downstreamtask}.csv')\n",
    "    file_exists = os.path.exists(log_path)\n",
    "    train_log.to_csv(log_path, mode='a', header=not file_exists, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdedca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading V_L300_U90.tul\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating:   0%|          | 0/218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 218/218 [00:23<00:00,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 64.249%,\n",
      "ACC@5: 87.643%,\n",
      "Macro-R: 48.096%,\n",
      "Macro-P: 47.513%,\n",
      "Macro-F1: 47.009%,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"loading {SAVE_NAME}.{downstreamtask}\")\n",
    "trajfm.load_state_dict(torch.load(os.path.join(MODEL_CACHE_DIR, f'{SAVE_NAME}.{downstreamtask}'), map_location=device))\n",
    "\n",
    "metrics, _ = test_user_model(model=trajfm, dataloader=test_dataloader, device = device)\n",
    "\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {round(value * 100, 3)}%,\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
