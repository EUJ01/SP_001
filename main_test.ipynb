{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c408ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import utils\n",
    "from models.trajfm import TrajFM\n",
    "from data import TrajFMDataset, PretrainPadder, fetch_task_padder, X_COL, Y_COL, coord_transform_GPS_UTM\n",
    "from torch.utils.data import random_split\n",
    "import warnings\n",
    "from pipeline import train_user_model, test_user_model\n",
    "import torch.multiprocessing as mp\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84217ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "SETTINGS_CACHE_DIR = os.environ.get('SETTINGS_CACHE_DIR', os.path.join('settings', 'cache'))\n",
    "MODEL_CACHE_DIR = os.environ.get('MODEL_CACHE_DIR', 'saved_model')\n",
    "LOG_SAVE_DIR = os.environ.get('LOG_SAVE_DIR', 'logs')\n",
    "PRED_SAVE_DIR = os.environ.get('PRED_SAVE_DIR', 'predictions')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
    "\n",
    "\n",
    "if mp.get_start_method(allow_none=True) is None:\n",
    "    mp.set_start_method('spawn')\n",
    "device = f'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "torch.backends.cuda.enable_math_sdp(True)\n",
    "# This key is an indicator of multiple things.\n",
    "datetime_key = utils.get_datetime_key()\n",
    "\n",
    "\n",
    "with open(os.path.join('settings', f'local_test.json'), 'r') as fp:\n",
    "    setting = json.load(fp)\n",
    "    setting = setting[0]\n",
    "utils.create_if_noexists(SETTINGS_CACHE_DIR)\n",
    "with open(os.path.join(SETTINGS_CACHE_DIR, f'{datetime_key}.json'), 'w') as fp:\n",
    "    json.dump(setting, fp)\n",
    "    \n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71773187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: ./dataset/geolife_U89_TrajAll_L1000.h5\n"
     ]
    }
   ],
   "source": [
    "SAVE_NAME = setting[\"save_name\"]\n",
    "\n",
    "train_traj_df = pd.read_hdf(setting['dataset']['train_traj_df'], key='trips')\n",
    "print(\"dataset:\", setting['dataset']['train_traj_df'])\n",
    "user_count = len(train_traj_df['user_id'].unique())\n",
    "traj_count = len(train_traj_df['traj_id'].unique())\n",
    "traj_len = len(train_traj_df['seq_i'])\n",
    "tao = train_traj_df['delta_t'].mean()\n",
    "setting[\"finetune\"][\"padder\"][\"params\"][\"num_users\"] = user_count\n",
    "\n",
    "scale = 4000\n",
    "# if \"chengdu\" in setting['dataset']['train_traj_df']:\n",
    "#     UTM_region = 48\n",
    "# if \"xian\" in setting['dataset']['train_traj_df']:\n",
    "#     UTM_region = 49\n",
    "if \"geolife\" in setting['dataset']['train_traj_df']:\n",
    "    UTM_region = 50\n",
    "        \n",
    "train_dataset = TrajFMDataset(traj_df=train_traj_df, UTM_region=UTM_region, scale = scale)\n",
    "\n",
    "poi_df = pd.read_hdf(setting['dataset']['poi_df'], key='pois')\n",
    "poi_embed = torch.from_numpy(np.load(setting['dataset']['poi_embed'])).float().to(device)\n",
    "\n",
    "poi_coors = poi_df[[X_COL, Y_COL]].to_numpy()\n",
    "poi_coors = (coord_transform_GPS_UTM(poi_coors, UTM_region) - train_dataset.spatial_middle_coord) / scale\n",
    "poi_coors = torch.tensor(poi_coors).float().to(device)\n",
    "\n",
    "# Build the learnable model.\n",
    "trajfm = TrajFM(poi_embed=poi_embed, \n",
    "                poi_coors=poi_coors, \n",
    "                UTM_region=UTM_region,\n",
    "                spatial_middle_coord = train_dataset.spatial_middle_coord, \n",
    "                scale = scale, \n",
    "                **setting['trajfm'],\n",
    "                user = user_count).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62886f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users : 89\n",
      "total_traj : 8317\n",
      "total_points : 5941128\n",
      "Data Filtering : ['25th to 75th quartile based on traj_len', 'traj_len > 30 points', 'delta_t > 1800s', 'traj/user > 30 traj', 'resampled traj to 1000 points max', 'user_number and seq_i recalculated']\n"
     ]
    }
   ],
   "source": [
    "data_summary = {\n",
    "    \"users\": user_count,\n",
    "    \"total_traj\": traj_count,           \n",
    "    \"total_points\": traj_len,\n",
    "    \"Data Filtering\": [ \n",
    "        \"25th to 75th quartile based on traj_len\", \n",
    "        \"traj_len > 30 points\", \n",
    "        \"delta_t > 1800s\",\n",
    "        \"traj/user > 30 traj\",\n",
    "        \"resampled traj to 1000 points max\",\n",
    "        \"user_number and seq_i recalculated\"]\n",
    "}\n",
    "\n",
    "for key, value in data_summary.items():\n",
    "    print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e20c8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(train_dataset)\n",
    "train_size = int(0.6 * total_size)\n",
    "val_test_size = total_size - train_size\n",
    "val_size = int(0.5 * val_test_size)\n",
    "test_size = val_test_size - val_size\n",
    "\n",
    "train_dataset, val_test_dataset = random_split(train_dataset, [train_size, val_test_size])\n",
    "val_dataset, test_dataset = random_split(val_test_dataset, [val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d56d6463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found, starting new\n"
     ]
    }
   ],
   "source": [
    "downstreamtask = setting['finetune']['padder']['name']\n",
    "\n",
    "file_path = f\"{SAVE_NAME}.{downstreamtask}\"\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"Loading model {file_path}\")\n",
    "    trajfm.load_state_dict(torch.load(os.path.join(MODEL_CACHE_DIR, f'{SAVE_NAME}.{downstreamtask}'), map_location=device))\n",
    "else:\n",
    "    print(\"Model not found, starting new\")\n",
    "    \n",
    "padder = fetch_task_padder(padder_name=setting['finetune']['padder']['name'], padder_params=setting['finetune']['padder']['params'])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, collate_fn=padder, **setting['finetune']['dataloader'])\n",
    "val_dataloader = DataLoader(val_dataset, collate_fn=padder, **setting['finetune']['dataloader'])\n",
    "test_dataloader = DataLoader(test_dataset, collate_fn=padder, **setting['finetune']['dataloader'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca23fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meuj01\u001b[0m (\u001b[33mSP_001\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/teamspace/studios/this_studio/wandb/run-20250423_190338-U89_TrajAll_L1000_v2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/SP_001/TrajFM%20TUL/runs/U89_TrajAll_L1000_v2' target=\"_blank\">U89_TrajAll_L1000_v2</a></strong> to <a href='https://wandb.ai/SP_001/TrajFM%20TUL' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/SP_001/TrajFM%20TUL' target=\"_blank\">https://wandb.ai/SP_001/TrajFM%20TUL</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/SP_001/TrajFM%20TUL/runs/U89_TrajAll_L1000_v2' target=\"_blank\">https://wandb.ai/SP_001/TrajFM%20TUL/runs/U89_TrajAll_L1000_v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run id is U89_TrajAll_L1000_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 52/52 [00:32<00:00,  1.61it/s]\n",
      "Training, avg loss: 3.881:   3%|▎         | 1/30 [01:30<43:45, 90.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 18.88%,\n",
      "ACC@5: 36.62%,\n",
      "Macro-R: 6.66%,\n",
      "Macro-P: 1.77%,\n",
      "Macro-F1: 2.68%,\n",
      "val_loss 3.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 52/52 [00:32<00:00,  1.60it/s]4s/it]\n",
      "Training, avg loss: 3.628:   7%|▋         | 2/30 [03:00<42:01, 90.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 23.63%,\n",
      "ACC@5: 42.22%,\n",
      "Macro-R: 10.29%,\n",
      "Macro-P: 4.98%,\n",
      "Macro-F1: 5.67%,\n",
      "val_loss 3.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 52/52 [00:32<00:00,  1.60it/s]6s/it]\n",
      "Training, avg loss: 3.358:  10%|█         | 3/30 [04:30<40:31, 90.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 27.84%,\n",
      "ACC@5: 50.39%,\n",
      "Macro-R: 13.81%,\n",
      "Macro-P: 8.37%,\n",
      "Macro-F1: 9.01%,\n",
      "val_loss 3.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 52/52 [00:32<00:00,  1.60it/s]7s/it]\n",
      "Training, avg loss: 2.982:  13%|█▎        | 4/30 [06:00<39:01, 90.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 38.67%,\n",
      "ACC@5: 58.69%,\n",
      "Macro-R: 23.39%,\n",
      "Macro-P: 15.93%,\n",
      "Macro-F1: 17.6%,\n",
      "val_loss 2.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 52/52 [00:32<00:00,  1.60it/s]5s/it]\n",
      "Training, avg loss: 2.638:  17%|█▋        | 5/30 [07:30<37:34, 90.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 45.71%,\n",
      "ACC@5: 68.55%,\n",
      "Macro-R: 28.3%,\n",
      "Macro-P: 23.21%,\n",
      "Macro-F1: 24.18%,\n",
      "val_loss 2.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 52/52 [00:32<00:00,  1.60it/s]6s/it]\n",
      "Training, avg loss: 2.285:  20%|██        | 6/30 [09:00<36:02, 90.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 49.67%,\n",
      "ACC@5: 72.82%,\n",
      "Macro-R: 32.6%,\n",
      "Macro-P: 27.4%,\n",
      "Macro-F1: 28.41%,\n",
      "val_loss 2.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "train_log, saved_model_state_dict = train_user_model(model=trajfm, \n",
    "                                                    train_dataloader=train_dataloader, \n",
    "                                                    val_dataloader=val_dataloader,\n",
    "                                                    device = device, \n",
    "                                                    **setting['finetune']['config'],\n",
    "                                                    data_summary = data_summary)\n",
    "\n",
    "if setting['finetune'].get('save', False):\n",
    "    # save model\n",
    "    utils.create_if_noexists(MODEL_CACHE_DIR)\n",
    "    torch.save(saved_model_state_dict, os.path.join(MODEL_CACHE_DIR, f'{SAVE_NAME}.{downstreamtask}'))\n",
    "    \n",
    "    # save log\n",
    "    log_dir = os.path.join(LOG_SAVE_DIR, SAVE_NAME)\n",
    "    utils.create_if_noexists(log_dir)\n",
    "    log_path = os.path.join(log_dir, f'{SAVE_NAME}_{downstreamtask}.csv')\n",
    "    file_exists = os.path.exists(log_path)\n",
    "    train_log.to_csv(log_path, mode='a', header=not file_exists, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abdedca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading config_test_v2.tul\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 26/26 [00:08<00:00,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 3.73%,\n",
      "ACC@5: 19.71%,\n",
      "Macro-R: 3.95%,\n",
      "Macro-P: 1.33%,\n",
      "Macro-F1: 1.37%,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"loading {SAVE_NAME}.{downstreamtask}\")\n",
    "trajfm.load_state_dict(torch.load(os.path.join(MODEL_CACHE_DIR, f'{SAVE_NAME}.{downstreamtask}'), map_location=device))\n",
    "\n",
    "metrics, _ = test_user_model(model=trajfm, dataloader=test_dataloader, device = device)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {round(value * 100, 2)}%,\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
