{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c408ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import utils\n",
    "from models.trajfm import TrajFM\n",
    "from data import TrajFMDataset, PretrainPadder, fetch_task_padder, X_COL, Y_COL, coord_transform_GPS_UTM\n",
    "from torch.utils.data import random_split\n",
    "import warnings\n",
    "from pipeline import train_user_model, test_user_model\n",
    "import torch.multiprocessing as mp\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84217ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "SETTINGS_CACHE_DIR = os.environ.get('SETTINGS_CACHE_DIR', os.path.join('settings', 'cache'))\n",
    "MODEL_CACHE_DIR = os.environ.get('MODEL_CACHE_DIR', 'saved_model')\n",
    "LOG_SAVE_DIR = os.environ.get('LOG_SAVE_DIR', 'logs')\n",
    "PRED_SAVE_DIR = os.environ.get('PRED_SAVE_DIR', 'predictions')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
    "\n",
    "\n",
    "if mp.get_start_method(allow_none=True) is None:\n",
    "    mp.set_start_method('spawn')\n",
    "device = f'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "torch.backends.cuda.enable_math_sdp(True)\n",
    "# This key is an indicator of multiple things.\n",
    "datetime_key = utils.get_datetime_key()\n",
    "\n",
    "\n",
    "with open(os.path.join('settings', f'local_test.json'), 'r') as fp:\n",
    "    setting = json.load(fp)\n",
    "    setting = setting[0]\n",
    "utils.create_if_noexists(SETTINGS_CACHE_DIR)\n",
    "with open(os.path.join(SETTINGS_CACHE_DIR, f'{datetime_key}.json'), 'w') as fp:\n",
    "    json.dump(setting, fp)\n",
    "    \n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71773187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: ./dataset/geolife_U56_Traj200_L200.h5\n"
     ]
    }
   ],
   "source": [
    "SAVE_NAME = setting[\"save_name\"]\n",
    "\n",
    "train_traj_df = pd.read_hdf(setting['dataset']['train_traj_df'], key='trips')\n",
    "print(\"dataset:\", setting['dataset']['train_traj_df'])\n",
    "user_count = len(train_traj_df['user_id'].unique())\n",
    "traj_count = len(train_traj_df['traj_id'].unique())\n",
    "traj_len = len(train_traj_df['seq_i'])\n",
    "tao = train_traj_df['delta_t'].mean()\n",
    "setting[\"finetune\"][\"padder\"][\"params\"][\"num_users\"] = user_count\n",
    "\n",
    "scale = 4000\n",
    "# if \"chengdu\" in setting['dataset']['train_traj_df']:\n",
    "#     UTM_region = 48\n",
    "# if \"xian\" in setting['dataset']['train_traj_df']:\n",
    "#     UTM_region = 49\n",
    "if \"geolife\" in setting['dataset']['train_traj_df']:\n",
    "    UTM_region = 50\n",
    "        \n",
    "train_dataset = TrajFMDataset(traj_df=train_traj_df, UTM_region=UTM_region, scale = scale)\n",
    "\n",
    "poi_df = pd.read_hdf(setting['dataset']['poi_df'], key='pois')\n",
    "poi_embed = torch.from_numpy(np.load(setting['dataset']['poi_embed'])).float().to(device)\n",
    "\n",
    "poi_coors = poi_df[[X_COL, Y_COL]].to_numpy()\n",
    "poi_coors = (coord_transform_GPS_UTM(poi_coors, UTM_region) - train_dataset.spatial_middle_coord) / scale\n",
    "poi_coors = torch.tensor(poi_coors).float().to(device)\n",
    "\n",
    "# Build the learnable model.\n",
    "trajfm = TrajFM(poi_embed=poi_embed, \n",
    "                poi_coors=poi_coors, \n",
    "                UTM_region=UTM_region,\n",
    "                spatial_middle_coord = train_dataset.spatial_middle_coord, \n",
    "                scale = scale, \n",
    "                **setting['trajfm'],\n",
    "                user = user_count).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a62886f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users : 56\n",
      "total_traj : 4138\n",
      "total_points : 781675\n",
      "Data Filtering : ['25th to 75th quartile based on traj_len', 'traj_len > 30 points', 'delta_t > 1800s', 'traj/user > 30 traj', 'resampled traj to 1000 points max', 'user_number and seq_i recalculated']\n"
     ]
    }
   ],
   "source": [
    "data_summary = {\n",
    "    \"users\": user_count,\n",
    "    \"total_traj\": traj_count,           \n",
    "    \"total_points\": traj_len,\n",
    "    \"Data Filtering\": [ \n",
    "        \"25th to 75th quartile based on traj_len\", \n",
    "        \"traj_len > 30 points\", \n",
    "        \"delta_t > 1800s\",\n",
    "        \"traj/user > 30 traj\",\n",
    "        \"resampled traj to 1000 points max\",\n",
    "        \"user_number and seq_i recalculated\"]\n",
    "}\n",
    "\n",
    "for key, value in data_summary.items():\n",
    "    print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e20c8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(train_dataset)\n",
    "train_size = int(0.6 * total_size)\n",
    "val_test_size = total_size - train_size\n",
    "val_size = int(0.5 * val_test_size)\n",
    "test_size = val_test_size - val_size\n",
    "\n",
    "train_dataset, val_test_dataset = random_split(train_dataset, [train_size, val_test_size])\n",
    "val_dataset, test_dataset = random_split(val_test_dataset, [val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d56d6463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found, starting new\n"
     ]
    }
   ],
   "source": [
    "downstreamtask = setting['finetune']['padder']['name']\n",
    "\n",
    "file_path = f\"{SAVE_NAME}.{downstreamtask}\"\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"Loading model {file_path}\")\n",
    "    trajfm.load_state_dict(torch.load(os.path.join(MODEL_CACHE_DIR, f'{SAVE_NAME}.{downstreamtask}'), map_location=device))\n",
    "else:\n",
    "    print(\"Model not found, starting new\")\n",
    "    \n",
    "padder = fetch_task_padder(padder_name=setting['finetune']['padder']['name'], padder_params=setting['finetune']['padder']['params'])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, collate_fn=padder, **setting['finetune']['dataloader'])\n",
    "val_dataloader = DataLoader(val_dataset, collate_fn=padder, **setting['finetune']['dataloader'])\n",
    "test_dataloader = DataLoader(test_dataset, collate_fn=padder, **setting['finetune']['dataloader'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fca23fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>ACC@1</td><td>▁▅█</td></tr><tr><td>ACC@5</td><td>▁█▁</td></tr><tr><td>Macro-F1</td><td>█▂▁</td></tr><tr><td>Macro-P</td><td>█▁▂</td></tr><tr><td>Macro-R</td><td>█▁▇</td></tr><tr><td>Train_Loss</td><td>█▁▁</td></tr><tr><td>Val_loss</td><td>█▂▁</td></tr><tr><td>epoch</td><td>▁▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ACC@1</td><td>3.86</td></tr><tr><td>ACC@5</td><td>17.14</td></tr><tr><td>Macro-F1</td><td>0.84</td></tr><tr><td>Macro-P</td><td>0.79</td></tr><tr><td>Macro-R</td><td>3.44</td></tr><tr><td>Train_Loss</td><td>3.96298</td></tr><tr><td>Val_loss</td><td>3.90439</td></tr><tr><td>epoch</td><td>3</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">config_test_v2</strong> at: <a href='https://wandb.ai/SP_001/TrajFM%20TUL/runs/config_test_v2' target=\"_blank\">https://wandb.ai/SP_001/TrajFM%20TUL/runs/config_test_v2</a><br> View project at: <a href='https://wandb.ai/SP_001/TrajFM%20TUL' target=\"_blank\">https://wandb.ai/SP_001/TrajFM%20TUL</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250423_183300-config_test_v2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/teamspace/studios/this_studio/wandb/run-20250423_183552-config_test_v2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/SP_001/TrajFM%20TUL/runs/config_test_v2' target=\"_blank\">config_test_v2</a></strong> to <a href='https://wandb.ai/SP_001/TrajFM%20TUL' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/SP_001/TrajFM%20TUL' target=\"_blank\">https://wandb.ai/SP_001/TrajFM%20TUL</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/SP_001/TrajFM%20TUL/runs/config_test_v2' target=\"_blank\">https://wandb.ai/SP_001/TrajFM%20TUL/runs/config_test_v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run id is config_test_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 26/26 [00:08<00:00,  2.95it/s]\n",
      "Training, avg loss: 3.90515:  33%|███▎      | 1/3 [00:19<00:39, 19.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 3.022%,\n",
      "ACC@5: 18.836%,\n",
      "Macro-R: 2.241%,\n",
      "Macro-P: 0.353%,\n",
      "Macro-F1: 0.584%,\n",
      "val_loss 3.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 26/26 [00:08<00:00,  2.98it/s]72s/it]\n",
      "Training, avg loss: 3.88490:  67%|██████▋   | 2/3 [00:39<00:19, 19.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 4.842%,\n",
      "ACC@5: 18.716%,\n",
      "Macro-R: 3.518%,\n",
      "Macro-P: 0.689%,\n",
      "Macro-F1: 0.771%,\n",
      "val_loss 3.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 26/26 [00:08<00:00,  3.00it/s]76s/it]\n",
      "Training, avg loss: 3.88062: 100%|██████████| 3/3 [00:59<00:00, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 4.104%,\n",
      "ACC@5: 20.192%,\n",
      "Macro-R: 3.538%,\n",
      "Macro-P: 0.998%,\n",
      "Macro-F1: 1.102%,\n",
      "val_loss 3.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_log, saved_model_state_dict = train_user_model(model=trajfm, \n",
    "                                                    train_dataloader=train_dataloader, \n",
    "                                                    val_dataloader=val_dataloader,\n",
    "                                                    device = device, \n",
    "                                                    **setting['finetune']['config'],\n",
    "                                                    data_summary = data_summary)\n",
    "\n",
    "if setting['finetune'].get('save', False):\n",
    "    # save model\n",
    "    utils.create_if_noexists(MODEL_CACHE_DIR)\n",
    "    torch.save(saved_model_state_dict, os.path.join(MODEL_CACHE_DIR, f'{SAVE_NAME}.{downstreamtask}'))\n",
    "    \n",
    "    # save log\n",
    "    log_dir = os.path.join(LOG_SAVE_DIR, SAVE_NAME)\n",
    "    utils.create_if_noexists(log_dir)\n",
    "    log_path = os.path.join(log_dir, f'{SAVE_NAME}_{downstreamtask}.csv')\n",
    "    file_exists = os.path.exists(log_path)\n",
    "    train_log.to_csv(log_path, mode='a', header=not file_exists, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abdedca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading config_test_v2.tul\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing/Validating: 100%|██████████| 26/26 [00:08<00:00,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC@1: 3.73%,\n",
      "ACC@5: 19.71%,\n",
      "Macro-R: 3.95%,\n",
      "Macro-P: 1.33%,\n",
      "Macro-F1: 1.37%,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"loading {SAVE_NAME}.{downstreamtask}\")\n",
    "trajfm.load_state_dict(torch.load(os.path.join(MODEL_CACHE_DIR, f'{SAVE_NAME}.{downstreamtask}'), map_location=device))\n",
    "\n",
    "metrics, _ = test_user_model(model=trajfm, dataloader=test_dataloader, device = device)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {round(value * 100, 2)}%,\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
